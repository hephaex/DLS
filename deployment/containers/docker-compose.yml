# CLAUDE DLS Docker Compose Configuration
# Complete production stack deployment

version: '3.8'

networks:
  claude_network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/16

volumes:
  postgres_data:
  prometheus_data:
  grafana_data:
  claude_images:
  claude_tftp:
  claude_logs:

services:
  # PostgreSQL Database
  postgres:
    image: postgres:14-alpine
    container_name: claude_postgres
    environment:
      POSTGRES_DB: claude_dls_production
      POSTGRES_USER: claude_dls
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secure_password_change_me}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./configs/postgres/postgresql.conf:/etc/postgresql/postgresql.conf
      - ./configs/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    networks:
      claude_network:
        ipv4_address: 172.20.0.10
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U claude_dls -d claude_dls_production"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # CLAUDE DLS Main Application
  claude_dls:
    build:
      context: ../..
      dockerfile: deployment/containers/Dockerfile
    container_name: claude_dls_server
    environment:
      RUST_LOG: ${RUST_LOG:-info}
      DATABASE_URL: postgresql://claude_dls:${POSTGRES_PASSWORD:-secure_password_change_me}@postgres:5432/claude_dls_production
      BIND_ADDRESS: 0.0.0.0:8080
      CLAUDE_CONFIG_PATH: /opt/claude_dls/config
      CLAUDE_DATA_PATH: /var/lib/claude_dls
      JWT_SECRET: ${JWT_SECRET:-your_jwt_secret_key_change_me}
      ZFS_POOL: claude_images
    volumes:
      - claude_images:/var/lib/claude_dls/images
      - claude_tftp:/var/lib/claude_dls/tftp
      - claude_logs:/opt/claude_dls/logs
      - ./configs/production.toml:/opt/claude_dls/config/production.toml:ro
    ports:
      - "8080:8080"
      - "67:67/udp"    # DHCP
      - "69:69/udp"    # TFTP
      - "3260:3260"    # iSCSI
      - "9090:9090"    # Metrics endpoint
    networks:
      claude_network:
        ipv4_address: 172.20.0.20
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped
    privileged: true  # Required for iSCSI and network operations
    cap_add:
      - NET_ADMIN
      - SYS_ADMIN
    logging:
      driver: json-file
      options:
        max-size: "50m"
        max-file: "5"

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: claude_prometheus
    volumes:
      - prometheus_data:/prometheus
      - ./configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./configs/prometheus/rules.yml:/etc/prometheus/rules.yml:ro
    ports:
      - "9091:9090"
    networks:
      claude_network:
        ipv4_address: 172.20.0.30
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
      - '--web.external-url=http://localhost:9091'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:10.1.0
    container_name: claude_grafana
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin123}
      GF_SERVER_HTTP_PORT: 3000
      GF_SERVER_DOMAIN: localhost
      GF_USERS_ALLOW_SIGN_UP: false
      GF_SECURITY_SECRET_KEY: ${GRAFANA_SECRET:-change_me_secret_key}
      GF_INSTALL_PLUGINS: grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./configs/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./configs/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "3000:3000"
    networks:
      claude_network:
        ipv4_address: 172.20.0.40
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

  # Redis for caching (optional)
  redis:
    image: redis:7-alpine
    container_name: claude_redis
    volumes:
      - ./configs/redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    ports:
      - "6379:6379"
    networks:
      claude_network:
        ipv4_address: 172.20.0.50
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "5m"
        max-file: "3"

  # NGINX Reverse Proxy
  nginx:
    image: nginx:1.25-alpine
    container_name: claude_nginx
    volumes:
      - ./configs/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./configs/nginx/claude.conf:/etc/nginx/conf.d/claude.conf:ro
      - ./configs/ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    networks:
      claude_network:
        ipv4_address: 172.20.0.60
    depends_on:
      - claude_dls
      - grafana
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"

# Additional services for production (optional)

  # Log aggregation (ELK stack alternative)
  loki:
    image: grafana/loki:2.9.0
    container_name: claude_loki
    volumes:
      - ./configs/loki/loki.yml:/etc/loki/local-config.yaml:ro
    ports:
      - "3100:3100"
    networks:
      claude_network:
        ipv4_address: 172.20.0.70
    command: -config.file=/etc/loki/local-config.yaml
    restart: unless-stopped

  # Log collector
  promtail:
    image: grafana/promtail:2.9.0
    container_name: claude_promtail
    volumes:
      - ./configs/promtail/promtail.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - claude_logs:/opt/claude_dls/logs:ro
    networks:
      - claude_network
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    restart: unless-stopped

  # Backup service
  backup:
    image: postgres:14-alpine
    container_name: claude_backup
    environment:
      PGPASSWORD: ${POSTGRES_PASSWORD:-secure_password_change_me}
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/usr/local/bin/backup.sh:ro
    networks:
      - claude_network
    depends_on:
      - postgres
    command: crond -f -d 0
    restart: unless-stopped

# Health check service
  healthcheck:
    image: alpine:3.18
    container_name: claude_healthcheck
    volumes:
      - ./scripts/healthcheck.sh:/usr/local/bin/healthcheck.sh:ro
    networks:
      - claude_network
    command: sh -c "apk add --no-cache curl && /usr/local/bin/healthcheck.sh"
    depends_on:
      - claude_dls
      - postgres
      - prometheus
      - grafana
    restart: "no"